{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bRHeFAU_3Kh"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "XMjFhUAkANDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"knkarthick/dialogsum\")"
      ],
      "metadata": {
        "id": "dD0ue1Gr_-VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "9exhd-EtAApo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][1]['dialogue']"
      ],
      "metadata": {
        "id": "SSAwfDhQAjOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Fine Tunning The Dataset"
      ],
      "metadata": {
        "id": "DHjH3T9bAt80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Z9DyHoHkAs0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "kMiTgKC3Aorl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here i am using the summarization to make the text summarize"
      ],
      "metadata": {
        "id": "Sk3uWuUcClK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline('summarization' , model='facebook/bart-large-cnn')"
      ],
      "metadata": {
        "id": "cZPvdgUFBsBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_1 = ds['train'][1]['dialogue']\n"
      ],
      "metadata": {
        "id": "58XK4DyJB2ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(article_1, max_length=40,min_length=10,do_sample=False)"
      ],
      "metadata": {
        "id": "oQh965s9C1Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][1]['summary']"
      ],
      "metadata": {
        "id": "lAJztZk0C2wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Fine Tunning The Dataset"
      ],
      "metadata": {
        "id": "ytC1fjeaDW_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This type of method we are using the BART transformers this way\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load tokenizer and TensorFlow-compatible model\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained('facebook/bart-large-cnn')\n"
      ],
      "metadata": {
        "id": "XnVWyS42DTRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "    source = batch['dialogue']\n",
        "    target = batch['summary']\n",
        "\n",
        "    # Tokenize inputs and labels\n",
        "    model_inputs = tokenizer(source, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    labels = tokenizer(target, max_length=128, padding=\"max_length\", truncation=True)\n",
        "\n",
        "    # Replace pad tokens with -100 in labels\n",
        "    label_ids = [\n",
        "        [token if token != tokenizer.pad_token_id else -100 for token in label]\n",
        "        for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = label_ids\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "GedPSqlDIZSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(preprocess, batched=True)"
      ],
      "metadata": {
        "id": "W_YK1-XyL9Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ds['train'].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=True,\n",
        "    batch_size=8,\n",
        ")"
      ],
      "metadata": {
        "id": "a_jpkgluMy6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ds['test'].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        ")"
      ],
      "metadata": {
        "id": "RPQcY4Dz3rsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "import tensorflow as tf\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "4Yf6_Jl73yM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=2)"
      ],
      "metadata": {
        "id": "-Az2grUa33u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving The Model"
      ],
      "metadata": {
        "id": "v3dzKkXdkclI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Save model and tokenizer to a directory\n",
        "model.save_pretrained('/content/model_directory')\n",
        "tokenizer.save_pretrained('/content/model_directory')"
      ],
      "metadata": {
        "id": "beTF9qb6k02x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForSeq2SeqLM.from_pretrained('/content/model_directory')\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/model_directory')"
      ],
      "metadata": {
        "id": "6CbGUhgU4nwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "    # Tokenize input using TensorFlow tensors\n",
        "    inputs = tokenizer(text, max_length=1024, truncation=True, return_tensors='tf')\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=150,\n",
        "        min_length=40,\n",
        "        length_penalty=2.0,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode generated tokens to text\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "B6LQOeHOlam4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library[5][6] that aims to make building user interfaces based on components more \"seamless\".[5] It is maintained by Meta (formerly Facebook) and a community of individual developers and companies.[7][8][9]\n",
        "\n",
        "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and Remix[a]. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality.[11][12] A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements.\"\"\"\n",
        "summary = summarize(text)\n",
        "print(f'Summary: {summary}')"
      ],
      "metadata": {
        "id": "1r1oQwuSmE9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "YqPaHkrYmkg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "    fn=summarize,\n",
        "    inputs=gr.Textbox(lines=10, label=\"Enter Text to Summarize\"),\n",
        "    outputs=gr.Textbox(label=\"Summary\"),\n",
        "    title=\"Text Summarizer\",\n",
        "    description=\"This app uses a TensorFlow Transformer model to summarize long text into concise form.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "OHOakHYVFVKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "enlfM0haHfDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}